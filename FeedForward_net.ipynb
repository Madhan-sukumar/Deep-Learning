{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7uDkn3tul6SHd4DyxDGZo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Madhan-sukumar/Deep-Learning/blob/main/FeedForward_net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " - **torch** - torch is the main module that holds all the things you need for Tensor computation.\n",
        " - **torch.nn and torch.nn.functional** - The torch.nn module provides many classes and functions to build neural networks. Can think of it as the fundamental building blocks of neural networks: models, all kinds of layers, activation functions, parameter classes, etc. It allows us to build the model like putting some LEGO set together.\n",
        "\n",
        " - **torch.optim** - torch.optim offers all the optimizers like SGD, ADAM, etc., so don’t have to write it from scratch.\n",
        "\n",
        " - **torchvision** - torchvision contains a lot of popular datasets, model architectures, and common image transformations for computer vision. We get our MNIST dataset from it and also use its transforms.\n",
        "\n",
        "- **SummaryWriter (Tensor Board)** - SummaryWriter enables PyTorch to generate the report for Tensor Board. We’ll use Tensor Board to look at our training data, compare results and gain intuition. \n",
        "\n"
      ],
      "metadata": {
        "id": "ET097LN8faB3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**About the Dataset:**\n",
        "\n",
        "The MNIST dataset, also known as the Modified National Institute of Standards and Technology dataset, consists of 60,000 small square 28×28 grayscale images of handwritten digits between 0 to 9 divided into ten different classes. This dataset is mainly used for text classification using deep learning models.\n",
        "\n",
        "To create a Feed-Forward classification model on the MNIST dataset,\n",
        "\n",
        " 1. Use DataLoader module from Pytorch to load our dataset and Transform It\n",
        " 2. We will implement Neural Net, with input, hidden & output Layer\n",
        " 3. Apply Activation Functions \n",
        " 4. Set up the Loss & Optimizer and implement a Training Loop that can use batch training\n",
        " 5. Finally, evaluate the model and calculate our accuracy. "
      ],
      "metadata": {
        "id": "f1BBZlS8C14k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBAyXaGZxCox"
      },
      "outputs": [],
      "source": [
        "# imorting dependencies\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "F__jkgNDAaP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will first define our hyperparameters for our neural network; we are setting our input size to 784 as we know that our dataset contains images of the size 28×28 and flatten this into a one-dimensional array. "
      ],
      "metadata": {
        "id": "aGI5fusN7I6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#hyperparameters tuning\n",
        "input_size = 784 #28x28px input size \n",
        "hidden_size = 100\n",
        "num_classess = 10 # output size or number of classes from 0 to 9\n",
        "num_epochs = 2\n",
        "batch_size = 100\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "ybOxIH8YyRcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the dataset from MNIST\n",
        "#converting the data to tensor using transform\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data',train=True,\n",
        "                                           transform = transforms.ToTensor(),download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data',train=False,\n",
        "                                           transform = transforms.ToTensor())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5po7QTOzlbV",
        "outputId": "29d35f57-2f2e-4e5a-f00e-1fa113e49eeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 159370850.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 75239561.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 36500477.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 13875111.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Loaders\n",
        "train_loaders = DataLoader(dataset= train_dataset, batch_size = batch_size,shuffle = True)\n",
        "test_loaders = DataLoader(dataset= test_dataset, batch_size = batch_size,shuffle = False)"
      ],
      "metadata": {
        "id": "IA6Xh_Qj0PwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to see \n",
        "examples= iter(train_loaders)\n",
        "samples, labels = next(examples)\n",
        "print(samples.shape,labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLn4ru2x1dVz",
        "outputId": "ce629642-8e1c-412d-854d-1b290dd1c21b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It shows, we having 100 batches of images and the colour channel is 1, its size is 28x28"
      ],
      "metadata": {
        "id": "-MtLM8jy1-4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# viewing the sample data\n",
        "for i in range(6):\n",
        "  plt.subplot(2,3,i+1)\n",
        "  plt.imshow(samples[i][0],cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "TuZR_Nr01qV_",
        "outputId": "d1491e44-06e6-41ab-93e7-5873530c90dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FULLY CONNECTED NN"
      ],
      "metadata": {
        "id": "nLl3V4Ss3mt9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a Fully connected neural network with one hidden layer. We will not be not using the Softmax function here as cross-entropy loss implemented further will apply it automatically. "
      ],
      "metadata": {
        "id": "LkjNZmOc3p2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size,num_classess):\n",
        "    super(NeuralNet, self).__init__()\n",
        "    #creatin linear layer\n",
        "    self.l1 = nn.Linear(input_size,hidden_size) \n",
        "    #applying activation function\n",
        "    self.relu = nn.ReLU()\n",
        "    #linear layer at end\n",
        "    self.l2 = nn.Linear(hidden_size,num_classess)\n",
        "\n",
        "  #defining forward, x will get the sample as input\n",
        "  def forward(self,x):\n",
        "    out = self.l1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.l2(out)\n",
        "    return out\n",
        "\n",
        "model =NeuralNet(input_size,hidden_size,num_classess)"
      ],
      "metadata": {
        "id": "ESDdAIQh3o7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOSS FUNCTIONS AND OPTIMISER "
      ],
      "metadata": {
        "id": "mOQ_RQev9kag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr= learning_rate)"
      ],
      "metadata": {
        "id": "Rc2Ub59-9LHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRAINING LOOP"
      ],
      "metadata": {
        "id": "2fWTTaCR-sTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "n_total_steps = len(train_loaders)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loaders):  # i -index\n",
        "        # origin shape: [100, 1, 28, 28]\n",
        "        # resized: [100, 784 as 1d]\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device) #pushing the images to GPU to get GPU support\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if (i+1) % 100 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRCygQMn-rn0",
        "outputId": "64aac5fc-c2e9-488b-ec35-c528c050ce7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/2], Step [100/600], Loss: 0.4681\n",
            "Epoch [1/2], Step [200/600], Loss: 0.3681\n",
            "Epoch [1/2], Step [300/600], Loss: 0.2163\n",
            "Epoch [1/2], Step [400/600], Loss: 0.2302\n",
            "Epoch [1/2], Step [500/600], Loss: 0.1957\n",
            "Epoch [1/2], Step [600/600], Loss: 0.1385\n",
            "Epoch [2/2], Step [100/600], Loss: 0.1436\n",
            "Epoch [2/2], Step [200/600], Loss: 0.2121\n",
            "Epoch [2/2], Step [300/600], Loss: 0.1390\n",
            "Epoch [2/2], Step [400/600], Loss: 0.1511\n",
            "Epoch [2/2], Step [500/600], Loss: 0.3441\n",
            "Epoch [2/2], Step [600/600], Loss: 0.2230\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TESTING"
      ],
      "metadata": {
        "id": "7H1bRvvLB1a7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    for images, labels in test_loaders:\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        #prediction\n",
        "        outputs = model(images)\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs.data, 1) # 1 to return index 1\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network on the 10000 test images: {acc} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_TIdDuxAm6u",
        "outputId": "a6abc3f2-8bb1-488f-9250-de3220949f6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 95.19 %\n"
          ]
        }
      ]
    }
  ]
}